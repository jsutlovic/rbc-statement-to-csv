{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830987cb-b6f1-48ca-a32d-74210caca063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import typing\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from decimal import Decimal\n",
    "from functools import partial\n",
    "from io import StringIO\n",
    "from itertools import groupby, starmap, takewhile\n",
    "from pathlib import Path\n",
    "from typing import List, Iterator, NamedTuple, Optional\n",
    "\n",
    "from dateutil.parser import parse as date_parse\n",
    "from parsel import Selector\n",
    "from pdfminer.high_level import extract_text_to_fp\n",
    "from pdfminer.layout import LAParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f12756-32e3-4e51-b73a-df2560fc8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(\"parser\")\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f002553-51b2-4ff3-9fc1-44b6a560decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate XML file:\n",
    "# pdf2txt.py --output_type xml --outfile - -A -L 0.51 -F +0.8 -V test_may_2023.pdf | xmllint --format - > test_may_2023_new.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655bf3d-0c47-48cf-bef5-ec001f858403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBox(NamedTuple):\n",
    "    left: float\n",
    "    bottom: float\n",
    "    right: float\n",
    "    top: float\n",
    "\n",
    "def process_bbox(tag: Selector) -> BBox:\n",
    "    # Expect a comma-separated list of 4 coordinates in order: left, top, right, bottom\n",
    "    # Parse them into a list of strings\n",
    "    str_coords = tag.attrib.get(\"bbox\", \"0,0,0,0\").split(\",\")\n",
    "    # Use map to convert to a list of floats\n",
    "    coords = map(float, str_coords)\n",
    "    # Unpack coords\n",
    "    return BBox(*coords)\n",
    "\n",
    "def bounding_bbox(first: BBox, last: BBox) -> BBox:\n",
    "    return BBox(first.left, first.bottom, last.right, last.top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889b81de-f165-46bd-b65d-fa5c69a0bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextLine(NamedTuple):\n",
    "    bbox: BBox\n",
    "    parent_id: int\n",
    "    text: str\n",
    "    font: str\n",
    "    size: str\n",
    "\n",
    "def process_textline(textline: Selector) -> TextLine:\n",
    "    bbox = process_bbox(textline)\n",
    "    text = \"\".join(textline.xpath(\"./text/text()\").getall()).strip()\n",
    "    parent_id = int(textline.xpath(\"parent::textbox/@id\").get())\n",
    "    font = textline.xpath(\"text/@font\").get()\n",
    "    size = float(textline.xpath(\"text/@size\").get())\n",
    "    return TextLine(bbox, parent_id, text, font, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a1a432-491b-4e99-9a4e-059d1d3cc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinePart(NamedTuple):\n",
    "    bbox: BBox\n",
    "\n",
    "class Separator(NamedTuple):\n",
    "    bbox: BBox\n",
    "\n",
    "def process_linepart(linepart: Selector) -> LinePart:\n",
    "    bbox = process_bbox(linepart)\n",
    "    return LinePart(bbox)\n",
    "\n",
    "def process_separator(lineparts: List[LinePart]) -> Separator:\n",
    "    bbox = bounding_bbox(lineparts[0].bbox, lineparts[-1].bbox)\n",
    "    return Separator(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893bd25-a890-4fa5-8cc1-365c3d9d5396",
   "metadata": {},
   "outputs": [],
   "source": [
    "details_sentinel = \"Details of your account\"\n",
    "date_matcher = re.compile(r\"^From (.+) to (.+)$\")\n",
    "page_number_matcher = re.compile(\"^(\\d+) of (\\d+)$\")\n",
    "\n",
    "Component = TextLine|Separator\n",
    "Components = List[Component]\n",
    "\n",
    "\n",
    "class Page(NamedTuple):\n",
    "    start_date: datetime.date\n",
    "    end_date: datetime.date\n",
    "    components: Components\n",
    "\n",
    "\n",
    "def process_page_components(page_tag: Selector) -> Page:\n",
    "    page_id = page_tag.attrib.get(\"id\", \"0\")\n",
    "    log.info(f\"Processing page {page_id}\")\n",
    "\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    page_transaction_components = []\n",
    "    sentinel_found = None\n",
    "    \n",
    "    # Find all textboxes that are not vertical and are larger than size 8\n",
    "    for textline_tag in page_tag.xpath(\".//textbox[not(@wmode = 'vertical')]/textline[text/@size >= 8]\"):\n",
    "        textline = process_textline(textline_tag)\n",
    "        log.info(f\"Textline: {textline.bbox}; {textline.font}@{textline.size}\\n{textline.text}\")\n",
    "        page_transaction_components.append(textline)\n",
    "\n",
    "        if textline.text.startswith(details_sentinel):\n",
    "            log.info(f\"sentinel found: {textline.text!r}\")\n",
    "            sentinel_found = textline\n",
    "        if date_matcher.match(textline.text):\n",
    "            log.info(f\"found page dates: {textline}\")\n",
    "            try:\n",
    "                start_date_str, end_date_str = date_matcher.match(textline.text).groups()\n",
    "                start_date = date_parse(start_date_str).date()\n",
    "                end_date = date_parse(end_date_str).date()\n",
    "            except Exception as exc:\n",
    "                log.warning(f\"Could not parse dates: {exc}\")\n",
    "        elif page_number_matcher.match(textline.text):\n",
    "            # Skip page numbers\n",
    "            page_transaction_components.pop()\n",
    "\n",
    "    sep_lines = []\n",
    "    # Filter for all lines\n",
    "    for line_tag in page_tag.xpath(\".//line\"):\n",
    "        linepart = process_linepart(line_tag)\n",
    "        \n",
    "        # Ignore lines that are not below the sentinel\n",
    "        # Vertical coordinates start from the bottom of the page\n",
    "        if sentinel_found is not None and linepart.bbox.bottom > sentinel_found.bbox.bottom:\n",
    "            continue\n",
    "\n",
    "        first_linepart = next(iter(sep_lines), None)\n",
    "        if first_linepart is None or first_linepart.bbox.bottom == linepart.bbox.bottom:\n",
    "            sep_lines.append(linepart)\n",
    "        else:\n",
    "            sep = process_separator(sep_lines)\n",
    "            log.info(f\"Separator: {sep}\")\n",
    "            page_transaction_components.append(sep)\n",
    "            sep_lines = [linepart]\n",
    "    else:\n",
    "        if sep_lines:\n",
    "            sep = process_separator(sep_lines)\n",
    "            page_transaction_components.append(sep)\n",
    "\n",
    "    # Sort the parsed transaction components vertically (inversed), then horizontally\n",
    "    page_transaction_components.sort(key=lambda item: (-(item.bbox.top), item.bbox.left))\n",
    "\n",
    "    # Didn't find sentinel, so there probably aren't transactions here\n",
    "    if sentinel_found is None:\n",
    "        return Page(start_date=start_date, end_date=end_date, components=[])\n",
    "\n",
    "    # Take all items after sentinel\n",
    "    sentinel_index = page_transaction_components.index(sentinel_found)\n",
    "    if sentinel_index == -1:\n",
    "        raise\n",
    "    if len(page_transaction_components) < sentinel_index+1:\n",
    "        raise\n",
    "\n",
    "    return Page(start_date=start_date, end_date=end_date, components=page_transaction_components[sentinel_index+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481bbc1-ea0f-49b2-bc6b-ea190dbcd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_date = re.compile(r\"[$,]\")\n",
    "\n",
    "transaction_fields = [\"date\", \"description\", \"withdrawals\", \"deposits\", \"balance\"]\n",
    "transaction_field_types = [datetime.date, str, Decimal, Decimal, Decimal]\n",
    "\n",
    "class Transaction(NamedTuple):\n",
    "    date: datetime.date\n",
    "    description: str = \"\"\n",
    "    withdrawals: Optional[Decimal] = None\n",
    "    deposits: Optional[Decimal] = None\n",
    "    balance: Optional[Decimal] = None\n",
    "\n",
    "def take_transaction_components(components: Iterator[Component]) -> Components:\n",
    "    \"\"\"\n",
    "    Accumulate all the components considered part of a single transaction.\n",
    "    A transaction is defined as all the Components until a Separator is encountered.\n",
    "    \"\"\"\n",
    "    not_separator = lambda item: type(item) != Separator\n",
    "    tx_components = []\n",
    "    for item in takewhile(not_separator, components):\n",
    "        tx_components.append(item)\n",
    "    return tx_components\n",
    "\n",
    "def validate_transaction_headers(header_text: List[TextLine]) -> bool:\n",
    "    if len(header_text) != len(transaction_fields):\n",
    "        return False\n",
    "\n",
    "    # Ensure headers are Text types\n",
    "    types_match = [type(text) == TextLine for text in header_text]\n",
    "    if not all(types_match):\n",
    "        return False\n",
    "    \n",
    "    # Ensure all header text fields match expected transaction fields\n",
    "    # TODO: sort headers and fields?\n",
    "    fields_match = [\n",
    "        header_text.text.lower().startswith(fieldname)\n",
    "        for header_text, fieldname in zip(header_text, transaction_fields)\n",
    "    ]\n",
    "    return all(fields_match)\n",
    "\n",
    "def map_component_to_field(header_fields: dict[str, TextLine], component: TextLine) -> (str, TextLine):\n",
    "    field_name = \"\"\n",
    "\n",
    "    def is_aligned(field: str, a: Component, b: Component, threshold: float = 10.0):\n",
    "        a_field = getattr(a.bbox, field)\n",
    "        b_field = getattr(b.bbox, field)\n",
    "        return abs(a_field - b_field) < threshold\n",
    "\n",
    "    for field, field_type in zip(transaction_fields, transaction_field_types):\n",
    "        header_component = header_fields.get(field, None)\n",
    "        if not header_component:\n",
    "            continue\n",
    "\n",
    "        # Numeric fields will be right-aligned, so check if right bounds are close\n",
    "        if field_type == Decimal and is_aligned(\"right\", header_component, component, 2.0):\n",
    "            field_name = field\n",
    "            break\n",
    "        elif is_aligned(\"left\", header_component, component, 8.0):\n",
    "            field_name = field\n",
    "            break\n",
    "\n",
    "    return field_name, component\n",
    "\n",
    "def page_to_transactions(page: Page, description_separator=\" \") -> List[Transaction]:\n",
    "    it_components = iter(page.components)\n",
    "\n",
    "    # First line should be headers\n",
    "    header_components = take_transaction_components(it_components)\n",
    "\n",
    "    if not validate_transaction_headers(header_components):\n",
    "        raise Exception(f\"Invalid headers! {header_components}\")\n",
    "\n",
    "    # Map fields to header components: {\"date\": TextLine, \"description\": TextLine, ...}\n",
    "    header_fields = dict(zip(transaction_fields, header_components))\n",
    "    header_mapper = partial(map_component_to_field, header_fields)\n",
    "    transactions = []\n",
    "\n",
    "    last_date = page.start_date\n",
    "    tx_field_types = typing.get_type_hints(Transaction)\n",
    "    while True:\n",
    "        tx_components = take_transaction_components(it_components)\n",
    "        if not tx_components:\n",
    "            break\n",
    "\n",
    "        tx_dict = {}\n",
    "        # Collect final transaction component info\n",
    "        # Final type conversion for dates and Decimal\n",
    "        for component in tx_components:\n",
    "            key, comp = header_mapper(component)\n",
    "            key_type = tx_field_types.get(key, None)\n",
    "            \n",
    "            if issubclass(str, key_type):\n",
    "                tx_dict[key] = tx_dict.get(key, []) + [comp.text]\n",
    "            if issubclass(datetime.date, key_type):\n",
    "                try:\n",
    "                    date = date_parse(comp.text, default=last_date)\n",
    "\n",
    "                    # This probably means we're in a new year\n",
    "                    if date < last_date:\n",
    "                        date = date.replace(year=page.end_date.year)\n",
    "\n",
    "                    last_date = date\n",
    "                    tx_dict[key] = date\n",
    "\n",
    "                except Exception as exc:\n",
    "                    log.warning(f\"Bad date: {comp.text!r} ({exc})\")\n",
    "            if issubclass(Decimal, key_type):\n",
    "                try:\n",
    "                    n = Decimal(clean_date.sub(\"\", comp.text))\n",
    "                    tx_dict[key] = n\n",
    "                except:\n",
    "                    log.warning(f\"Bad decimal: {comp.text!r}\")\n",
    "\n",
    "        if tx_dict:\n",
    "            if not \"date\" in tx_dict:\n",
    "                tx_dict[\"date\"] = last_date\n",
    "            tx_dict[\"description\"] = description_separator.join(tx_dict[\"description\"])\n",
    "            transactions.append(Transaction(**tx_dict))\n",
    "\n",
    "    return transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aae92f-0ef1-406a-8177-f8b9e54eb740",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def parse_xml_doc(filename: str|Path) -> List[Transaction]:\n",
    "    with open(filename, \"r\") as fp:\n",
    "        xmlraw = fp.read()\n",
    "\n",
    "    try:\n",
    "        doc = Selector(text=xmlraw, type=\"xml\")\n",
    "    except:\n",
    "        log.error(f\"Could not parse {filename} as XML\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return parse_xml(doc)\n",
    "\n",
    "def parse_xml(doc: Selector) -> List[Transaction]:\n",
    "    all_transactions = []\n",
    "\n",
    "    for page in doc.xpath(\"./page\"):\n",
    "        page_id = page.attrib.get(\"id\", \"0\")\n",
    "        log.info(f\"Processing page {page_id}\\n\")\n",
    "        page_comp = process_page_components(page)\n",
    "\n",
    "        # Skip pages with no components (might just be text)\n",
    "        if not page_comp.components:\n",
    "            continue\n",
    "\n",
    "        page_transactions = page_to_transactions(page_comp)\n",
    "        all_transactions += page_transactions\n",
    "    \n",
    "    return all_transactions\n",
    "\n",
    "def tabulate_results(res: List[Transaction]):\n",
    "    # tabulate_tx = list(map(lambda tx: [tx.get(k, None) for k in transaction_fields], all_transactions))\n",
    "    full_table = tabulate(\n",
    "        res,\n",
    "        headers=transaction_fields,\n",
    "        tablefmt=\"rounded_grid\",\n",
    "        numalign=\"right\",\n",
    "        floatfmt=\".2f\",\n",
    "    )\n",
    "\n",
    "    print(full_table)\n",
    "\n",
    "tabulate_results(parse_xml_doc(Path(\".\") / \"test_dec_2022_new.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e330651-a722-4519-86a0-31b4f2ce3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pdf_doc(filename: str|Path) -> List[Transaction]:\n",
    "    xml_data = StringIO()\n",
    "    layout_params = {'detect_vertical': True, 'line_overlap': 0.51, 'all_texts': True, 'boxes_flow': 0.8}\n",
    "    with open(filename, \"rb\") as fp:\n",
    "        extract_text_to_fp(inf=fp, outfp=xml_data, output_type=\"xml\", laparams=LAParams(**layout_params), codec=None)\n",
    "\n",
    "    try:\n",
    "        doc = Selector(text=xml_data.getvalue(), type=\"xml\")\n",
    "    except:\n",
    "        log.error(f\"Could not parse {filename} as XML\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    return parse_xml(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c771029-9ba7-45c9-bdb5-bcbce00c8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulate_results(parse_pdf_doc(Path(\".\") / \"test_dec_2022.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13590fa3-d0ec-413f-9a5d-ab360c60c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "issubclass(Decimal, typing.get_type_hints(Transaction)[\"balance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28886dc2-654d-4358-9b8c-1541f1ca5ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
